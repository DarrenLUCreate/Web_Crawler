# Instagram Selenium Crawler

## Introduction  
IG對於現代人來說，是一個很重要的社交軟體，在年輕世代佔有具足輕重的地位，是一個可以大量獲取個人訊息的平台  
為此，我前幾天寫了一個爬蟲，專門針對IG的帳號做操作，目前使已經進行了初步測試，登入，追蹤，以及退追蹤的功能已經測試完成  

## 程式部分說明

### 登入  
1. 由於我並不希望我的個人機敏資料外流，造成資訊安全上的風險，我在程式外引進了INI檔，並利用ConfigParser由外部引入我的資料
2. 由於IG的反爬蟲做的蠻好的，我需要使用到ActionChains模擬滑鼠的操作進行登入，遇到的難點會在下一部份說明  

### 追蹤 
1. 當我輸入的關鍵字為追蹤的時候，我的爬蟲會跳到追蹤的判斷式進行判斷  
2. 我去觀察每個IG個人帳號的主頁，可以發現到格式都是'https://www.instagram.com/帳戶名字/'，我直接get方式直接到該帳戶主頁
3. 接下來我需要找到追蹤的按鈕，但按鈕的class name 是由好幾個小class name跟空白格組成起來的，如果直接複製該class會找不到標的  
4. 為了防止找不到的風險，導致程式需要時常修改，我將class_name跟Xpath一起寫進一個list裡面，並利用迴圈進行測試

### 退追蹤
1. 其實概念上跟追蹤其實一樣，但是多了一個確認退追蹤的按鈕

### 貼文內容
目前我發現以網頁的方式滾動IG的頁面，一次會出現12篇貼文，去看開發人員工具時會發現query_hash這個檔案  
發現到裡面正好有每次的新的12篇文章資料，目前正在嘗試找出首12篇文章，以及如何取的資料的方法

## 爬蟲遇到的情況與難點
IG的反爬蟲做得很好，當我使用Selenium登入時，若沒有進行等待與視窗最大化的話，IG會登入不了  
IG登入後，需要進行等待才能跳轉，如果登入後直接跳轉，IG會判定是爬蟲，自動登出，這裡我是用強制等待結合random的方式  
接下來登入後，去看看原始碼，發現幾乎所有功能的class_name都是以小class加空格組成，這樣需要去尋找裡面的唯一值，或使用另外的方式  
最後我使用了最簡單暴力的XPATH與CLASS_NAME，將使用的方法與標的寫成字典，在組成list進行迭迨，以防需要時常維修的狀況  

## 專案的優化
1. 撰寫腳本，並執行自動化爬蟲
2. 結合Django，將我所有的爬蟲整合成一個APP，方便我執行爬蟲作業
